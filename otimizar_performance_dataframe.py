#!/usr/bin/env python3
"""
Script para otimizar performance dos DataFrames fragmentados
Corrige os warnings de "DataFrame is highly fragmented"
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.ai_engine import AITradingEngine
from src.market_regime import MarketRegimeDetector

def otimizar_ai_engine():
    """Otimizar m√©todo de prepara√ß√£o de features do AI Engine"""
    
    print("üîß OTIMIZANDO AI ENGINE - Performance de DataFrames")
    print("=" * 60)
    
    # Arquivo de destino
    ai_engine_file = "src/ai_engine.py"
    
    # Ler o arquivo atual
    with open(ai_engine_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Encontrar a fun√ß√£o _prepare_regime_features e otimizar
    old_method = '''        # Adicionar features derivadas dos regimes
        for score_col in regime_scores:
            if score_col in df.columns:
                # Features atuais
                df[f'{score_col}_current'] = df[score_col]
                
                # Changes and momentum
                df[f'{score_col}_change'] = df[score_col].diff()
                
                # Volatility and stability metrics
                df[f'{score_col}_stability'] = df[score_col].rolling(10).std()
                
                # Percentile ranking
                rolling_window = min(len(df), 50)
                df[f'{score_col}_percentile'] = df[score_col].rolling(rolling_window).rank(pct=True)'''
    
    new_method = '''        # Adicionar features derivadas dos regimes (Otimizado - sem fragmenta√ß√£o)
        features_to_add = {}
        
        for score_col in regime_scores:
            if score_col in df.columns:
                col_data = df[score_col]
                
                # Calcular todas as features de uma vez para evitar fragmenta√ß√£o
                features_to_add[f'{score_col}_current'] = col_data
                features_to_add[f'{score_col}_change'] = col_data.diff()
                features_to_add[f'{score_col}_stability'] = col_data.rolling(10).std()
                
                rolling_window = min(len(df), 50)
                features_to_add[f'{score_col}_percentile'] = col_data.rolling(rolling_window).rank(pct=True)
        
        # Adicionar todas as features de uma vez usando pd.concat
        if features_to_add:
            import pandas as pd
            new_features_df = pd.DataFrame(features_to_add, index=df.index)
            df = pd.concat([df, new_features_df], axis=1)'''
    
    # Substituir na fun√ß√£o
    if old_method in content:
        content = content.replace(old_method, new_method)
        print("‚úÖ Otimizada fun√ß√£o _prepare_regime_features")
    else:
        print("‚ö†Ô∏è Padr√£o n√£o encontrado em _prepare_regime_features")
    
    # Otimizar tamb√©m a se√ß√£o de smoothing
    old_smoothing = '''        # Smooth out volatile features
        volatile_features = [col for col in df.columns if any(x in col.lower() for x in ['score', 'strength', 'change'])]
        for col in volatile_features:
            if col in df.columns and df[col].dtype in ['float64', 'int64']:
                df[f'{col}_smooth'] = df[col].rolling(5).mean()
                
                # Add shock detection
                col_diff = df[col].diff()
                df[f'{col}_shock'] = abs(col_diff) > df[col].rolling(20).std() * 2'''
    
    new_smoothing = '''        # Smooth out volatile features (Otimizado)
        volatile_features = [col for col in df.columns if any(x in col.lower() for x in ['score', 'strength', 'change'])]
        smoothing_features = {}
        
        for col in volatile_features:
            if col in df.columns and df[col].dtype in ['float64', 'int64']:
                col_data = df[col]
                smoothing_features[f'{col}_smooth'] = col_data.rolling(5).mean()
                
                # Add shock detection
                col_diff = col_data.diff()
                smoothing_features[f'{col}_shock'] = abs(col_diff) > col_data.rolling(20).std() * 2
        
        # Adicionar features de smoothing de uma vez
        if smoothing_features:
            smoothing_df = pd.DataFrame(smoothing_features, index=df.index)
            df = pd.concat([df, smoothing_df], axis=1)'''
    
    if old_smoothing in content:
        content = content.replace(old_smoothing, new_smoothing)
        print("‚úÖ Otimizada se√ß√£o de smoothing")
    else:
        print("‚ö†Ô∏è Padr√£o de smoothing n√£o encontrado")
    
    # Salvar arquivo otimizado
    with open(ai_engine_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("‚úÖ AI Engine otimizado com sucesso!")

def otimizar_market_regime():
    """Otimizar o MarketRegimeAnalyzer"""
    
    print("\nüîß OTIMIZANDO MARKET REGIME - Performance de DataFrames")
    print("=" * 60)
    
    regime_file = "src/market_regime.py"
    
    with open(regime_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Otimizar adi√ß√£o de features nos regimes
    old_pattern = "df['clustering_regime'] = regime_names"
    
    if old_pattern in content:
        # Encontrar a se√ß√£o que adiciona m√∫ltiplas colunas
        old_section = '''        df['clustering_regime'] = regime_names
        df['clustering_regime_id'] = cluster_labels'''
        
        new_section = '''        # Adicionar features de clustering de uma vez (Otimizado)
        clustering_features = pd.DataFrame({
            'clustering_regime': regime_names,
            'clustering_regime_id': cluster_labels
        }, index=df.index)
        df = pd.concat([df, clustering_features], axis=1)'''
        
        if old_section in content:
            content = content.replace(old_section, new_section)
            print("‚úÖ Otimizada se√ß√£o de clustering")
    
    # Otimizar correlations
    old_corr_pattern = "df['correlation_regime'] = correlation_regime"
    if old_corr_pattern in content:
        old_corr_section = '''        df['correlation_regime'] = correlation_regime
        df['correlation_strength'] = avg_correlation'''
        
        new_corr_section = '''        # Adicionar features de correla√ß√£o de uma vez (Otimizado)
        correlation_features = pd.DataFrame({
            'correlation_regime': correlation_regime,
            'correlation_strength': avg_correlation
        }, index=df.index)
        df = pd.concat([df, correlation_features], axis=1)'''
        
        if old_corr_section in content:
            content = content.replace(old_corr_section, new_corr_section)
            print("‚úÖ Otimizada se√ß√£o de correla√ß√£o")
    
    # Otimizar ensemble features
    old_ensemble_pattern = "df['ensemble_regime_score'] = ensemble_score"
    if old_ensemble_pattern in content:
        # Encontrar a se√ß√£o inteira de ensemble
        start_marker = "df['ensemble_regime_score'] = ensemble_score"
        end_marker = "df['ensemble_regime'] = ensemble_regime"
        
        start_idx = content.find(start_marker)
        end_idx = content.find(end_marker) + len(end_marker)
        
        if start_idx != -1 and end_idx != -1:
            new_ensemble_section = '''        # Adicionar features de ensemble de uma vez (Otimizado)
        ensemble_features = pd.DataFrame({
            'ensemble_regime_score': ensemble_score,
            'ensemble_regime': ensemble_regime
        }, index=df.index)
        df = pd.concat([df, ensemble_features], axis=1)'''
        
        old_ensemble_section = content[start_idx:end_idx]
        content = content.replace(old_ensemble_section, new_ensemble_section)
        print("‚úÖ Otimizada se√ß√£o de ensemble")
    
    with open(regime_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("‚úÖ Market Regime otimizado com sucesso!")

def criar_funcao_otimizada_concat():
    """Criar fun√ß√£o helper para concatena√ß√£o otimizada"""
    
    print("\nüîß CRIANDO FUN√á√ÉO HELPER DE CONCATENA√á√ÉO")
    print("=" * 50)
    
    helper_code = '''
def concat_features_optimized(df, new_features_dict):
    """
    Fun√ß√£o otimizada para adicionar m√∫ltiplas features ao DataFrame
    sem causar fragmenta√ß√£o
    
    Args:
        df: DataFrame principal
        new_features_dict: Dicion√°rio com {nome_coluna: Series/array}
    
    Returns:
        DataFrame com as novas features adicionadas
    """
    if not new_features_dict:
        return df
    
    try:
        import pandas as pd
        
        # Criar DataFrame com as novas features
        new_features_df = pd.DataFrame(new_features_dict, index=df.index)
        
        # Concatenar uma √∫nica vez
        result_df = pd.concat([df, new_features_df], axis=1)
        
        return result_df
        
    except Exception as e:
        # Fallback para m√©todo tradicional se houver erro
        print(f"Warning: Fallback para m√©todo tradicional devido a erro: {e}")
        result_df = df.copy()
        for col_name, col_data in new_features_dict.items():
            result_df[col_name] = col_data
        return result_df
'''
    
    # Adicionar ao final do ai_engine.py
    ai_engine_file = "src/ai_engine.py"
    
    with open(ai_engine_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Verificar se j√° existe
    if "concat_features_optimized" not in content:
        # Adicionar antes da √∫ltima linha (que geralmente √© a classe)
        content = content.rstrip() + helper_code + "\n"
        
        with open(ai_engine_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("‚úÖ Fun√ß√£o helper adicionada ao ai_engine.py")
    else:
        print("‚úÖ Fun√ß√£o helper j√° existe")

def testar_otimizacoes():
    """Testar se as otimiza√ß√µes funcionam"""
    
    print("\nüß™ TESTANDO OTIMIZA√á√ïES")
    print("=" * 40)
    
    try:
        from src.config import Config
        from src.market_data import MarketDataManager
        
        config = Config()
        market_data = MarketDataManager(config)
        ai_engine = AITradingEngine(config)
        
        # Testar com dados pequenos
        df = market_data.get_historical_data('BTCUSDT', '1h', 100)
        
        if df is not None and not df.empty:
            print(f"‚úÖ Dados obtidos: {len(df)} registros")
              # Testar prepara√ß√£o de features
            try:
                features_df = ai_engine.prepare_features(df)
                print(f"‚úÖ Features preparadas: {len(features_df.columns)} colunas")
                print("‚úÖ Otimiza√ß√µes funcionando corretamente!")
                
            except Exception as e:
                print(f"‚ùå Erro na prepara√ß√£o de features: {e}")
                
        else:
            print("‚ö†Ô∏è N√£o foi poss√≠vel obter dados para teste")
            
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")

def main():
    """Fun√ß√£o principal"""
    
    print("üöÄ INICIANDO OTIMIZA√á√ÉO DE PERFORMANCE")
    print("=" * 70)
    print("Objetivo: Eliminar warnings de DataFrame fragmentado")
    print("M√©todo: Usar pd.concat ao inv√©s de m√∫ltiplas inser√ß√µes")
    print()
    
    try:
        # 1. Otimizar AI Engine
        otimizar_ai_engine()
        
        # 2. Otimizar Market Regime
        otimizar_market_regime() 
        
        # 3. Criar fun√ß√£o helper
        criar_funcao_otimizada_concat()
        
        # 4. Testar otimiza√ß√µes
        testar_otimizacoes()
        
        print("\n" + "=" * 70)
        print("üéâ OTIMIZA√á√ÉO CONCLU√çDA COM SUCESSO!")
        print()
        print("üìä RESULTADOS ESPERADOS:")
        print("  ‚úÖ Elimina√ß√£o dos warnings de DataFrame fragmentado")
        print("  ‚úÖ Melhoria na performance de prepara√ß√£o de features")
        print("  ‚úÖ Redu√ß√£o no tempo de processamento")
        print("  ‚úÖ Menor uso de mem√≥ria")
        print()
        print("üîÑ PR√ìXIMOS PASSOS:")
        print("  1. Executar teste de vi√©s novamente")
        print("  2. Verificar se warnings foram eliminados") 
        print("  3. Medir melhoria de performance")
        
    except Exception as e:
        print(f"\n‚ùå ERRO DURANTE OTIMIZA√á√ÉO: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
