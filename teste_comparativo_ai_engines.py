#!/usr/bin/env python3
"""
üß™ TESTE COMPARATIVO COMPLETO - AI ENGINES
Compara todas as engines dispon√≠veis e escolhe a melhor
"""

import os
import sys
import time
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
import warnings
import json
warnings.filterwarnings('ignore')

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importar todas as engines dispon√≠veis
try:
    from src.ai_engine import AITradingEngine
    from ai_engine_ultra_enhanced import UltraEnhancedAIEngine
    from ai_engine_v3_otimizado import OptimizedAIEngineV3
    from ai_engine_ultra_fast import UltraFastAIEngine
    from src.config import Config
    from src.market_data import MarketDataManager
    ENGINES_AVAILABLE = True
except ImportError as e:
    logger.error(f"Erro ao importar engines: {e}")
    ENGINES_AVAILABLE = False

class AIEngineComparator:
    """Comparador completo de AI Engines"""
    
    def __init__(self):
        self.config = Config()
        self.market_data = MarketDataManager(self.config)
        self.results = {}
        self.test_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
        self.test_timeframes = ['1h', '4h']
        
        # Engines para testar
        self.engines = {
            'AITradingEngine': None,
            'UltraEnhancedAIEngine': None, 
            'OptimizedAIEngineV3': None,
            'UltraFastAIEngine': None
        }
        
    def initialize_engines(self):
        """Inicializar todas as engines"""
        logger.info("üöÄ Inicializando todas as AI Engines...")
        
        try:
            self.engines['AITradingEngine'] = AITradingEngine(self.config)
            logger.info("‚úÖ AITradingEngine inicializada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar AITradingEngine: {e}")
            
        try:
            self.engines['UltraEnhancedAIEngine'] = UltraEnhancedAIEngine(self.config)
            logger.info("‚úÖ UltraEnhancedAIEngine inicializada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar UltraEnhancedAIEngine: {e}")
            
        try:
            self.engines['OptimizedAIEngineV3'] = OptimizedAIEngineV3(self.config)
            logger.info("‚úÖ OptimizedAIEngineV3 inicializada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar OptimizedAIEngineV3: {e}")
            
        try:
            self.engines['UltraFastAIEngine'] = UltraFastAIEngine(self.config)
            logger.info("‚úÖ UltraFastAIEngine inicializada")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar UltraFastAIEngine: {e}")
    
    def generate_test_data(self, symbol: str, timeframe: str) -> pd.DataFrame:
        """Gerar dados de teste sint√©ticos"""
        logger.info(f"üìä Gerando dados de teste para {symbol} {timeframe}")
        
        # Simular 1000 pontos de dados hist√≥ricos
        dates = pd.date_range(end=datetime.now(), periods=1000, freq='1H')
        
        # Gerar dados OHLCV sint√©ticos mais realistas
        np.random.seed(42)  # Para resultados reproduz√≠veis
        
        # Pre√ßo base baseado no s√≠mbolo
        base_prices = {
            'BTCUSDT': 50000,
            'ETHUSDT': 3000,
            'BNBUSDT': 400
        }
        base_price = base_prices.get(symbol, 1000)
        
        # Simula√ß√£o de movimento de pre√ßos com tend√™ncia
        returns = np.random.normal(0.0001, 0.02, len(dates))  # Retornos com drift positivo
        prices = [base_price]
        
        for i in range(1, len(dates)):
            price = prices[-1] * (1 + returns[i])
            prices.append(max(price, base_price * 0.5))  # Evitar pre√ßos negativos
        
        # Criar OHLCV
        df = pd.DataFrame({
            'timestamp': dates,
            'open': prices,
            'high': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
            'low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
            'close': prices,
            'volume': np.random.lognormal(15, 1, len(dates))  # Volume log-normal
        })
        
        # Garantir que high >= low >= 0
        df['high'] = df[['open', 'close', 'high']].max(axis=1)
        df['low'] = df[['open', 'close', 'low']].min(axis=1)
        
        logger.info(f"‚úÖ Dados gerados: {len(df)} pontos de {symbol}")
        return df
        
    def test_engine_performance(self, engine_name: str, engine, symbol: str, timeframe: str) -> Dict:
        """Testar performance de uma engine espec√≠fica"""
        logger.info(f"üß™ Testando {engine_name} com {symbol} {timeframe}")
        
        if engine is None:
            return {
                'error': 'Engine n√£o dispon√≠vel',
                'speed': float('inf'),
                'accuracy': 0.0,
                'signals_generated': 0
            }
        
        try:
            # Gerar dados de teste
            test_data = self.generate_test_data(symbol, timeframe)
            
            # Teste de velocidade
            start_time = time.time()
            
            # Simular gera√ß√£o de sinais
            signals_generated = 0
            errors = 0
            confidences = []
            
            # Testar com diferentes chunks de dados
            chunk_size = 100
            for i in range(0, len(test_data) - chunk_size, chunk_size):
                try:
                    data_chunk = test_data.iloc[i:i+chunk_size].copy()
                    
                    # Tentar gerar sinal dependendo do m√©todo da engine
                    signal = None
                    if hasattr(engine, 'generate_signal'):
                        signal = engine.generate_signal(data_chunk, symbol, timeframe)
                    elif hasattr(engine, 'predict_signal'):
                        signal = engine.predict_signal(data_chunk)
                    elif hasattr(engine, 'analyze_market'):
                        signal = engine.analyze_market(data_chunk, symbol)
                    
                    if signal and isinstance(signal, dict):
                        signals_generated += 1
                        if 'confidence' in signal:
                            confidences.append(signal['confidence'])
                    
                except Exception as e:
                    errors += 1
                    logger.debug(f"Erro em chunk {i}: {e}")
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # Calcular m√©tricas
            avg_confidence = np.mean(confidences) if confidences else 0.0
            success_rate = (signals_generated / (signals_generated + errors)) * 100 if (signals_generated + errors) > 0 else 0.0
            
            # Simular accuracy baseada em heur√≠sticas
            # (Em um teste real, comparar√≠amos com resultados conhecidos)
            simulated_accuracy = min(95.0, max(30.0, avg_confidence * 100 + np.random.normal(0, 5)))
            
            result = {
                'engine_name': engine_name,
                'symbol': symbol,
                'timeframe': timeframe,
                'processing_time': round(processing_time, 3),
                'signals_generated': signals_generated,
                'errors': errors,
                'success_rate': round(success_rate, 2),
                'avg_confidence': round(avg_confidence, 4),
                'simulated_accuracy': round(simulated_accuracy, 2),
                'speed_score': round(1000 / max(processing_time, 0.001), 2),  # Sinais por segundo
                'data_points_processed': len(test_data)
            }
            
            logger.info(f"‚úÖ {engine_name}: {signals_generated} sinais em {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro testando {engine_name}: {e}")
            return {
                'engine_name': engine_name,
                'error': str(e),
                'processing_time': float('inf'),
                'signals_generated': 0,
                'simulated_accuracy': 0.0,
                'speed_score': 0.0
            }
    
    def run_comprehensive_test(self):
        """Executar teste comparativo completo"""
        logger.info("üéØ INICIANDO TESTE COMPARATIVO COMPLETO DE AI ENGINES")
        logger.info("=" * 60)
        
        # Inicializar engines
        self.initialize_engines()
        
        # Executar testes para cada combina√ß√£o
        all_results = []
        
        for engine_name, engine in self.engines.items():
            logger.info(f"\nüîÑ Testando {engine_name}...")
            engine_results = []
            
            for symbol in self.test_symbols:
                for timeframe in self.test_timeframes:
                    result = self.test_engine_performance(engine_name, engine, symbol, timeframe)
                    engine_results.append(result)
                    all_results.append(result)
            
            # Calcular m√©tricas agregadas para esta engine
            if engine_results:
                avg_speed = np.mean([r.get('speed_score', 0) for r in engine_results])
                avg_accuracy = np.mean([r.get('simulated_accuracy', 0) for r in engine_results])
                total_signals = sum([r.get('signals_generated', 0) for r in engine_results])
                avg_processing_time = np.mean([r.get('processing_time', float('inf')) for r in engine_results if r.get('processing_time', float('inf')) != float('inf')])
                
                self.results[engine_name] = {
                    'avg_speed_score': round(avg_speed, 2),
                    'avg_accuracy': round(avg_accuracy, 2),
                    'total_signals': total_signals,
                    'avg_processing_time': round(avg_processing_time, 3),
                    'detailed_results': engine_results
                }
        
        # Salvar resultados detalhados
        self.save_results(all_results)
        
        # Analisar resultados
        self.analyze_results()
        
        return self.results
    
    def save_results(self, all_results):
        """Salvar resultados em arquivo JSON"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"ai_engine_comparison_{timestamp}.json"
        
        try:
            with open(filename, 'w') as f:
                json.dump(all_results, f, indent=2, default=str)
            logger.info(f"üìÅ Resultados salvos em: {filename}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar resultados: {e}")
    
    def analyze_results(self):
        """Analisar e ranking das engines"""
        logger.info("\n" + "=" * 60)
        logger.info("üìä AN√ÅLISE COMPARATIVA DOS RESULTADOS")
        logger.info("=" * 60)
        
        if not self.results:
            logger.error("‚ùå Nenhum resultado dispon√≠vel para an√°lise")
            return
        
        # Criar ranking baseado em m√∫ltiplos crit√©rios
        rankings = {}
        
        for engine_name, results in self.results.items():
            # Calcular score composto
            speed_score = results.get('avg_speed_score', 0)
            accuracy_score = results.get('avg_accuracy', 0)
            reliability_score = 100 - (100 / max(results.get('total_signals', 1), 1))  # Baseado em sinais gerados
            processing_efficiency = 1000 / max(results.get('avg_processing_time', 1), 0.001)
            
            # Score composto (pesos ajust√°veis)
            composite_score = (
                accuracy_score * 0.4 +           # 40% accuracy
                speed_score * 0.001 * 0.3 +      # 30% speed (normalizado)
                reliability_score * 0.2 +        # 20% reliability  
                processing_efficiency * 0.001 * 0.1  # 10% efficiency (normalizado)
            )
            
            rankings[engine_name] = {
                'composite_score': round(composite_score, 2),
                'accuracy': results.get('avg_accuracy', 0),
                'speed': results.get('avg_speed_score', 0),
                'reliability': round(reliability_score, 2),
                'efficiency': round(processing_efficiency, 2),
                'total_signals': results.get('total_signals', 0),
                'avg_time': results.get('avg_processing_time', 0)
            }
        
        # Ordenar por score composto
        sorted_engines = sorted(rankings.items(), key=lambda x: x[1]['composite_score'], reverse=True)
        
        # Exibir ranking
        logger.info("\nüèÜ RANKING FINAL DAS AI ENGINES:")
        logger.info("-" * 50)
        
        for i, (engine_name, scores) in enumerate(sorted_engines, 1):
            medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else f"{i}¬∫"
            logger.info(f"{medal} {engine_name}")
            logger.info(f"   Score Composto: {scores['composite_score']}")
            logger.info(f"   Accuracy: {scores['accuracy']:.1f}%")
            logger.info(f"   Speed Score: {scores['speed']:.1f}")
            logger.info(f"   Reliability: {scores['reliability']:.1f}%")
            logger.info(f"   Sinais Gerados: {scores['total_signals']}")
            logger.info(f"   Tempo M√©dio: {scores['avg_time']:.3f}s")
            logger.info("")
        
        # Recomenda√ß√£o final
        if sorted_engines:
            best_engine = sorted_engines[0]
            logger.info("üéØ RECOMENDA√á√ÉO FINAL:")
            logger.info(f"‚úÖ MELHOR ENGINE: {best_engine[0]}")
            logger.info(f"üìä Score: {best_engine[1]['composite_score']}")
            logger.info(f"üéØ Accuracy: {best_engine[1]['accuracy']:.1f}%")
            logger.info(f"‚ö° Speed: {best_engine[1]['speed']:.1f} ops/s")
            
            # Salvar recomenda√ß√£o
            self.save_recommendation(best_engine)
    
    def save_recommendation(self, best_engine):
        """Salvar recomenda√ß√£o da melhor engine"""
        recommendation = {
            'timestamp': datetime.now().isoformat(),
            'recommended_engine': best_engine[0],
            'scores': best_engine[1],
            'reasoning': f"Escolhida baseada no maior score composto ({best_engine[1]['composite_score']})",
            'implementation_guide': {
                'import_statement': f"from {best_engine[0].lower()} import {best_engine[0]}",
                'initialization': f"ai_engine = {best_engine[0]}(config)",
                'usage': "ai_engine.generate_signal(data, symbol, timeframe)"
            }
        }
        
        try:
            with open('ai_engine_recommendation.json', 'w') as f:
                json.dump(recommendation, f, indent=2)
            logger.info("üíæ Recomenda√ß√£o salva em: ai_engine_recommendation.json")
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar recomenda√ß√£o: {e}")

def main():
    """Fun√ß√£o principal"""
    print("üöÄ TESTE COMPARATIVO DE AI ENGINES - CRYPTO NINJA")
    print("=" * 60)
    
    if not ENGINES_AVAILABLE:
        print("‚ùå Engines n√£o dispon√≠veis. Verifique as importa√ß√µes.")
        return
    
    # Executar compara√ß√£o
    comparator = AIEngineComparator()
    results = comparator.run_comprehensive_test()
    
    print("\n‚úÖ Teste comparativo conclu√≠do!")
    print("üìÅ Verifique os arquivos gerados:")
    print("   - ai_engine_comparison_*.json (resultados detalhados)")
    print("   - ai_engine_recommendation.json (recomenda√ß√£o final)")

if __name__ == "__main__":
    main()
